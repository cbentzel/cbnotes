# 2024-12-24

Decided to start writing daily notes publicly, similar to how I do work internally at companies.

## RL - David Silver and Barto Sutton

Watching David Silver's [3rd Lecture](https://www.youtube.com/watch?v=Nd1-UUMVfz4) on RL focused on Dynamic Programming techniques for solving MDP solutions.

This includes a lot of examples from the Barto+Sutton book, such as gridworld or moving objects around.

The big notes of interest are:

* If you have a well-defined MDP, you can find an optimal policy and value function using a fairly straightforward path. This is kind of surprising, as I'd figure problem space wouldn't be convex enough to solve it.
* The solution feels a bit like how backprop works with training a network. You start with random weights/policies, and do a loop of forward pass/value evaluation with current policy, and then calculate an incremental step to improve things (gradient descent on loss function, or greedy choice of policy).
* Value iteration focuses on building up the value function for an MDP without building an actual policy along the way. But once you have optimal value function it is pretty trivial to develop an optimal policy.
* Why do value iteration rather than policy evaluation/policy iteration? The primary argument seems to be that it's a more efficient approach - maybe not in how many steps are needed to converge, but the cost of each step. Ultimately this looks like it's a max of O(a\*s^2) per step where a is the number of actions, and s is number of states in a fully connected graph.
* Most of the iteration steps involve updating all value functions of state S at step N+1 based on value function from step N. Other approaches like in-place versions will incrementally update state values rather than taking a snapshot. This is clearly more memory efficient. Not mentioned in lecture, but I could imagine this being worse on GPUs due to need for constant synchronization of updates - whereas the previous synchronous approach can have all states evaluated in parallel.
* Of course, in practice you don't actually have a full model of the MDP - and even if you did, the full size of an MDP may end up being too large to compute efficiently. The goal is to move towards something more sample based and model free to make this more efficient.

Other thoughts:

* [Link](https://www.cs.ubc.ca/~poole/demos/mdp/vi.html) to a web-based example of value iteration. But it's dependent on Java applet. Might be fun to rewrite in modern JS.


## Cursor 

I had started using Cursor instead of VS Code + Copilot on the fairly trivial Wordle clone. Some of the inline editing changes are pretty nice, but I haven't seen a drastic uptick in performance improvements. The one thing that is arguably better is Compose, but I haven't tried that yet. 

From a business perspective it seems like the best features that they do will just be copied by VS Code, so I have a hard time seeing that they have a sustainable advantage. Especially since the underlying LLMs are used by both (Claude Sonnet, 4o). 

Their business model also doesn't seem to allow for using something like Llama locally.

## Linear Programming

I read most of "An Illustrated Guide to Linear Programming" from Saul Bass which I had lying around the house. Very short book from 1970. 

Provides very intuitive basis for linear programming and more focused on problem setup and statements over the actual evaluation. This is actually a good approach because it is more focused on what problems are actually a good fit for linear programming than how to do the underlying solvers for it.

Only covers a 2D example of simplex method, which is fine. I haven't read the math appendix yet, which looks like it formalizes some of the other pieces in the book.

Most examples don't feel too dated, although there are fairly traditional gender roles representative of the time of authoring.

## Diablo 3

Playing Diablo 3 with my 11 year old on the Switch. It's really fun in co-op. Super fast progression early on. Get way overpowered quickly - need to probably make things harder.

## Random links

https://arxiv.org/pdf/2412.05265 overview of 144 papers in RL. Read after finishing Barto-Sutton and David Silver.