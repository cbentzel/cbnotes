# 2025-01-03

## RL

Going back to learning material, but I do need to run through some programming exercises.

Currently watching Lecture 4 of David Silver's RL course. This is focused on model-free value prediction from a fixed policy.

Idea is that we don't want to actually model the full MDP, but still understand value function for a specific policy via sampling (monte-carlo policy evaluation)